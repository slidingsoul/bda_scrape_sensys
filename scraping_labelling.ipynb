{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook untuk Data Scraping & Labelling\n",
    "Data discrape dari komentar video YouTube \"Jake Paul vs. Mike Tyson FIGHT HIGHLIGHTS ðŸ¥Š | ESPN Ringside\" https://www.youtube.com/watch?v=Aja2KfuoqGA dari channel ESPN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Key\n",
    "Apabila Anda ingin menjalankan notebook ini untuk melakukan overwrite pada dataset, Anda perlu mendapatkan API key dari Google Cloud Console terlebih dahulu\n",
    "1. Login ke Google Cloud Console\n",
    "2. Create New Project dan beri nama\n",
    "3. Buka \"API & Services\" > Library\n",
    "4. Cari \"YouTube Data API v3\" dan enable\n",
    "5. Pilih Public Data untuk Credential Type\n",
    "6. Create Credentials dan salin API key\n",
    "7. Buat file .env pada root directory\n",
    "8. Isi file .env dengan API_KEY=API_KEY_YANG_BARU_DISALIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referensi\n",
    "Potongan kode diambil dari https://www.geeksforgeeks.org/sentiment-analysis-of-youtube-comments/ dengan beberapa modifikasi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparasi Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impor library yang dibutuhkan\n",
    "from googleapiclient.discovery import build\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import re\n",
    "import emoji\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ambil API Key dari file .env\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "youtube = build(\"youtube\", \"v3\", developerKey=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aja2KfuoqGA\n"
     ]
    }
   ],
   "source": [
    "# mendapatkan id video dari URL\n",
    "VIDEO_URL = \"https://www.youtube.com/watch?v=Aja2KfuoqGA\"\n",
    "video_id = VIDEO_URL[-11:]\n",
    "print(video_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mendapatkan response dari video\n",
    "video_response = youtube.videos().list(\n",
    "    part=\"snippet\",\n",
    "    id=video_id\n",
    ").execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel id: UCiWLfSweyRNmLpgEHekhoAg\n"
     ]
    }
   ],
   "source": [
    "# mendapatkan snippet dan id uploader dari video\n",
    "video_snippet = video_response['items'][0]['snippet']\n",
    "uploader_channel_id = video_snippet['channelId']\n",
    "print(\"channel id: \" + uploader_channel_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memulai Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mengambil komentar dari video sebanyak 1000\n",
    "MAX_COMMENTS = 1000\n",
    "comments = []\n",
    "nextPageToken = None\n",
    "while len(comments) < MAX_COMMENTS:\n",
    "    request = youtube.commentThreads().list(\n",
    "        part='snippet',\n",
    "        videoId=video_id,\n",
    "        maxResults=100,  # You can fetch up to 100 comments per request\n",
    "        pageToken=nextPageToken\n",
    "    )\n",
    "    response = request.execute()\n",
    "    for item in response['items']:\n",
    "        comment = item['snippet']['topLevelComment']['snippet']\n",
    "        # Check if the comment is not from the video uploader\n",
    "        if comment['authorChannelId']['value'] != uploader_channel_id:\n",
    "            comments.append(comment['textDisplay'])\n",
    "    nextPageToken = response.get('nextPageToken')\n",
    "\n",
    "    if not nextPageToken:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why was Mikes right hand wrap missing at the announcement?\n",
      "Ngl thats cap\n",
      "Mike le gano 100%, mike es un gran guerrero.\n",
      "Wooooooow Mike Tayson es el mejor boxeador del Mundo.\n",
      "58æ­²çœŸçš„å·®å¾ˆå¤šï¼Œé–ƒé¿ï¼Œé«”åŠ›éƒ½æ¸›åŠäº†ï¼Œæ³°æ£®å¹´è¼•çš„æ™‚å€™é€™ç¨®å’–3å›žåˆå…§è‚¯å®šå€’ä¸‹......ä¹Ÿæ²’æœ‰ç¬¬äºŒäººèƒ½è·Ÿå·”å³°æ™‚æœŸçš„æ³°æ£®ç¡¬é‹¼ï¼Œé€™ç¨®å’–åªèƒ½è€è€æŠ±æŠ±æ‹³\n"
     ]
    }
   ],
   "source": [
    "# menunjukkan 5 komentar teratas\n",
    "for comment in comments[:5]:\n",
    "    print(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memulai filtering\n",
    "Filtering dilakukan untuk menghilangkan komentar yang berisi hyperlink dan komentar yang isinya lebih dari 35% emoji, serta komentar yang kosong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperlink_pattern = re.compile(\n",
    "    r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "\n",
    "threshold_ratio = 0.65\n",
    "\n",
    "relevant_comments = []\n",
    "\n",
    "# Inside your loop that processes comments\n",
    "for comment_text in comments:\n",
    "\n",
    "    comment_text = comment_text.lower().strip()\n",
    "\n",
    "    emojis = emoji.emoji_count(comment_text)\n",
    "\n",
    "    # Count text characters (excluding spaces)\n",
    "    text_characters = len(re.sub(r'\\s', '', comment_text))\n",
    "\n",
    "    if (any(char.isalnum() for char in comment_text)) and not hyperlink_pattern.search(comment_text):\n",
    "        if emojis == 0 or (text_characters / (text_characters + emojis)) > threshold_ratio:\n",
    "            relevant_comments.append(comment_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "why was mikes right hand wrap missing at the announcement?\n",
      "ngl thats cap\n",
      "mike le gano 100%, mike es un gran guerrero.\n",
      "wooooooow mike tayson es el mejor boxeador del mundo.\n",
      "58æ­²çœŸçš„å·®å¾ˆå¤šï¼Œé–ƒé¿ï¼Œé«”åŠ›éƒ½æ¸›åŠäº†ï¼Œæ³°æ£®å¹´è¼•çš„æ™‚å€™é€™ç¨®å’–3å›žåˆå…§è‚¯å®šå€’ä¸‹......ä¹Ÿæ²’æœ‰ç¬¬äºŒäººèƒ½è·Ÿå·”å³°æ™‚æœŸçš„æ³°æ£®ç¡¬é‹¼ï¼Œé€™ç¨®å’–åªèƒ½è€è€æŠ±æŠ±æ‹³\n"
     ]
    }
   ],
   "source": [
    "# Print the relevant comments\n",
    "for relevant_comment in relevant_comments[:5]:\n",
    "    print(relevant_comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Melanjutkan filtering\n",
    "Pada komentar kelima terlihat masih ada html element. Masih perlu dilakukan pembersihan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# membuat fungsi untuk mendapatkan teks saja dari HTML element\n",
    "def remove_html(comment):\n",
    "    return BeautifulSoup(comment, \"lxml\").get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BUDI\\AppData\\Local\\Temp\\ipykernel_38444\\434507644.py:3: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  return BeautifulSoup(comment, \"lxml\").get_text()\n"
     ]
    }
   ],
   "source": [
    "# membuat list yang berisi komentar bersih\n",
    "cleaned_comments = [remove_html(comment) for comment in relevant_comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "why was mikes right hand wrap missing at the announcement?\n",
      "ngl thats cap\n",
      "mike le gano 100%, mike es un gran guerrero.\n",
      "wooooooow mike tayson es el mejor boxeador del mundo.\n",
      "58æ­²çœŸçš„å·®å¾ˆå¤šï¼Œé–ƒé¿ï¼Œé«”åŠ›éƒ½æ¸›åŠäº†ï¼Œæ³°æ£®å¹´è¼•çš„æ™‚å€™é€™ç¨®å’–3å›žåˆå…§è‚¯å®šå€’ä¸‹......ä¹Ÿæ²’æœ‰ç¬¬äºŒäººèƒ½è·Ÿå·”å³°æ™‚æœŸçš„æ³°æ£®ç¡¬é‹¼ï¼Œé€™ç¨®å’–åªèƒ½è€è€æŠ±æŠ±æ‹³\n"
     ]
    }
   ],
   "source": [
    "# menunjukkan 5 komentar bersih teratas\n",
    "for cleaned_comment in cleaned_comments[:5]:\n",
    "    print(cleaned_comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparasi Labelling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengimpor fungsi yang dibutuhkan\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memulai Labelling\n",
    "Komentar yang bersih sudah didapatkan, tetapi kita tidak tahu sentimen dari setiap komentarnya. Terdapat 1000 komentar, akan memakan waktu lama untuk melakukan labelling secara manual. Oleh karena itu digunakan salah satu fungsi dari VADER yaitu SentimentIntensityAnalyzer. Polarity dari cleaned_comments akan dicari untuk mengetahui bagaimana sentimen dari video (menurut VADER). Sentiment diukur dalam bentuk polarity. Polarity yang lebih dari 0.05 akan dihitung positif, kurang dari -0.05 dihitung negatif, dan di antaranya dihitung netral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# membuat fungsi untuk mengambalikan polarity\n",
    "def sentiment_scores(comment, polarity):\n",
    "\n",
    "    # Creating a SentimentIntensityAnalyzer object.\n",
    "    sentiment_object = SentimentIntensityAnalyzer()\n",
    "\n",
    "    sentiment_dict = sentiment_object.polarity_scores(comment)\n",
    "    polarity.append(sentiment_dict['compound'])\n",
    "\n",
    "    return polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# membuat list yang menyimpan polarity setiap komentar, komentar negatif, positive, dan netral\n",
    "polarity = []\n",
    "positive_comments = []\n",
    "negative_comments = []\n",
    "neutral_comments = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mengkategorikan komentar menurut polarity-nya\n",
    "for index, items in enumerate(cleaned_comments):\n",
    "    polarity = sentiment_scores(items, polarity)\n",
    "\n",
    "    if polarity[-1] > 0.05:\n",
    "        positive_comments.append(items)\n",
    "    elif polarity[-1] < -0.05:\n",
    "        negative_comments.append(items)\n",
    "    else:\n",
    "        neutral_comments.append(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print(polarity[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mengukur Sentimen Video\n",
    "Sentimen dari video boxing Mike Tyson VS Jake Paul dapat diukur dari rata-rata polarity komentarnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Polarity: 0.02887009544008484\n",
      "The Video has got a Neutral response\n",
      "The comment with most positive sentiment: what a shamed,, how many years the age difference again???? lol lol lol lol please tag jake paul ðŸ¤£ðŸ¤£ðŸ¤£ðŸ¤£ðŸ¤£ðŸ¤£ðŸ¤£ðŸ¤£ðŸ¤£ðŸ¤£ðŸ¤£ðŸ¤£ðŸ¤£ðŸ¤£ðŸ¤£ðŸ¤£ðŸ¤£ðŸ¤£ðŸ¤£ with score 0.9968 and length 116\n",
      "The comment with most negative sentiment: why paul fight mike tyson mike tyson is old ðŸ˜¢ðŸ˜¢ðŸ˜¢ðŸ˜¢no one can understand ðŸ˜¢ðŸ˜¢ðŸ˜¢ðŸ˜¢ with score -0.9786 and length 74\n"
     ]
    }
   ],
   "source": [
    "avg_polarity = sum(polarity)/len(polarity)\n",
    "print(\"Average Polarity:\", avg_polarity)\n",
    "if avg_polarity > 0.05:\n",
    "    print(\"The Video has got a Positive response\")\n",
    "elif avg_polarity < -0.05:\n",
    "    print(\"The Video has got a Negative response\")\n",
    "else:\n",
    "    print(\"The Video has got a Neutral response\")\n",
    "\n",
    "print(\"The comment with most positive sentiment:\", cleaned_comments[polarity.index(max(\n",
    "    polarity))], \"with score\", max(polarity), \"and length\", len(cleaned_comments[polarity.index(max(polarity))]))\n",
    "print(\"The comment with most negative sentiment:\", cleaned_comments[polarity.index(min(\n",
    "    polarity))], \"with score\", min(polarity), \"and length\", len(cleaned_comments[polarity.index(min(polarity))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ekspor Dataset\n",
    "Untuk melakukan pelatihan dan pengujian model, komentar perlu diekspor ke bentuk yang dapat dibaca. Selain komentar, diekspor juga sentimennya antara positif, negatif, atau netral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengimpor pandas untuk ekspor ke .csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of tuples with comments and their respective labels\n",
    "data = [(comment, 'positive') for comment in positive_comments] + \\\n",
    "       [(comment, 'negative') for comment in negative_comments] + \\\n",
    "       [(comment, 'neutral') for comment in neutral_comments]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data, columns=['Comment', 'Label'])\n",
    "\n",
    "# Export to CSV\n",
    "df.to_csv('comments.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
